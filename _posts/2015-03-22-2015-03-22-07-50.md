---
layout: post
url: https://www.huxiu.com/article/110803
name: MIT Technology Review
time: 2015-03-22 07:50
title: 到底人工智能会不会统治世界？
---
虎嗅注：原文来自 MIT Technology Review，虎嗅编译。

几年前，有次我和一位正在创业的朋友喝咖啡。当时他刚刚过了 40 岁生日，父亲生病了，又经常背痛，他觉得自己被生活压得透不过气。“别笑话我，”他对我说，“我可是盼着奇点来临拯救我呢。”

我的这位朋友在科技行业工作，他目睹了微处理器的飞速发展和互联网的崛起。即便是在中年危机来到之前，想要让他相信机器智慧超越人类——也就是被未来学家称之为奇点的那一刻——也不是那么难。一种博爱的超级智慧或许能够迅速以更快的速度分析人类的基因密码，破解人类永葆青春的秘密。即便做不到这一点，或许至少能弄清楚如何解决背痛的问题。

但是如果它没有那么友好会怎样？牛津大学未来人类学院主任 (Future of Humanity at the University of Oxford) 尼克?博斯特姆 (Nick Bostrom) 在他的新书《超级智慧》(Superintelligence) 中描述了下面一种情况，这段内容也引发了一场有关未来人工智能的激烈辩论。试想一台我们可以称之为“纸夹最大器”(paper-clip maximizer) 的机器，它的程序被设置成生产尽可能多的纸夹。现在我们假设，这台机器变得超级智能了。因为其目标已经设置好，它可能会接着自己决定生产新型的、更有效率的纸夹制造机——直到有一天，就像米达斯 (King Midas) 一样，它从本质上将所有东西都变成了纸夹子。

不必担心，你可能会说：我们只要将其程序设置成生产 100 万个纸夹之后立刻停止就可以了。但是如果这台机器在生产了纸夹之后，又自己决定去检查制造的产品怎么办？检查计数是否准确怎么办？这台机器要变得更智能才可以确认这些问题。这台超级智能机器生产了一些还未被发明的粗糙计算材料 ——称之为“计算质”(computronium) 并将其用于判断每个疑问。但是每一个新的问题又随着接踵而来，如此反复，直到整个地球都转化为“计算质”。当然，除了那 100 万个纸夹之外。

博斯特姆并不认为“纸夹最大器”会发展成和上述情况一模一样，这只是一个思维试验。人们进行这种试验是为了说明，即便是再仔细的系统设计也可能无法控制机器智能的极端情况。但是他坚信超级智能会形成，并认为这种智能能发挥伟大的作用，但是也会自己决定不再需要周围的人类。

如果这种说法听起来让你觉得很荒谬，你不是一个人。机器人专家罗德尼?布鲁克斯 (Rodney Brooks) 就是批评者之一，他表示恐惧人工智能会失控的人误解了我们所说的电脑在思考或者电脑变得更智能。从这个角度来看，博斯特姆描述的所谓超级智能来临的日子还很远，甚至大概不可能实现。

但是却有许多有智慧有思想的学者同意博斯特姆的看法，表现出担忧。这是为什么呢？

“一台电脑能够思考吗？”这个问题从一开始就忽略了计算机科学。1950 阿兰?图灵 (Alan Turing) 提出一台机器能够像小孩子般思考；编程语言 LISP 的发明者约翰?麦卡锡 (John McCarthy) 在 1955 年提出用“人工智能”定义该领域。随着 1960 年代和 1970 年代的人工智能研究者开始使用电脑辨析图像、翻译语言并理解代脉之外的自然语言指令，一种认为电脑最终会发展出能够说话以及思考的能力——并且会做坏事——的看法，在主流大众文化中开始出现。电影《 2001 太空漫游》(HAL from 2001: A Space Odyssey) 和 1970 年的《巨人:福宾计划》(Colossus: The Forbin Project) 都出现了一台大型电脑将世界带到核毁灭边缘当中的剧情。同样的剧情在 13 年后也出现在《战争游戏》(WarGames) 当中，1973 年的《西部世界》(Westworld) 当中，机器人失去控制开始杀戮人类。

就在人工智能研究距离远大目标还相聚甚远的时候，资金支持开始枯竭，“人工智能的冬天”来了。即便如此，智能机器在 1980 年代和 90 年代的科幻作家中仍旧受到欢迎，正是科幻作家维纳?温哲 (Vernor Vinge) 让奇点这个概念大众化并流行。还有机器人研究学者汉斯?莫拉维克 (Hans Moravec)，工程师/创业者雷?库兹维尔 (Ray Kurzweil)，他们三个人认为：当电脑能够独立思考不同的目标实现方法时，很可能会具有自我反省的能力——这样它就能够改变软件，让自己变得更智能。不久之后，这种计算机将能够设计它自己的硬件。

正如库兹维尔所描述的，这种情况会开始一个美丽的新世界。这种机器将会具有洞察能力和耐心 (以万亿分之一秒计) 解决纳米科技和空间飞行中的问题；它们能够改进人体条件，让我们把自己的意识上传，变成一种永生的数字形式。智慧将在宇宙中自由传播。

你也可以找到和这种阳关乐观派恰恰相反的论调。史蒂芬?霍金 (Stephen Hawking) 就曾警告，因为人类无法在与高级人工智能的竞争中胜出，奇点“可能是人类末日的同义词”。在阅读了《超级智慧》一书之后，伊隆?马斯克 (Elon Musk) 发 Twitter 消息警诫世人，之后他向未来生命研究所 (Future of Life Institute) 捐赠了 1000 万美元。这家机构的目标就是要“努力排除人类现在面临的危机”(working to mitigate existential risks facing humanity)。

现在还没有人表示类似这种超级智能的东西已经存在了。实际上，我们还没有这种通用的人工智能技术，甚至是一个清晰的技术实现路线方案。人工智能领域最近的进展，从苹果的自动化助手 Siri 到谷歌的无人驾驶汽车，全都暴露了科学技术的严重缺陷：这两个产品都遇到了从未碰到的局面。人工神经网络能够自己学习判断照片里的猫，但是它们要看过成百上千副照片才行，而且对猫的判断准确率比一个小孩儿更低。

这也是诸如和布鲁克斯一样批评观点的来源，即便人工智能令人印象深刻——和早先的电脑能够做的事情相比——比如能够判断出图片中的一只猫，但机器并没有自主意志 (volition)，它不知道和猫类似的东西是什么，照片里描述的是怎样一种情况，也无法做到拥有人类不计可数的洞察力。从这个角度来说，人工智能可能会带来智能机器，但是想要实现博斯特姆想象中的场景，还需要太多太多的工作要做。即便那一天真的出现了，智能也并不一定会带来感知能力。基于目前人工智能的发展情况，就推测超级智能将会到来，就好像“看到更多高效内燃机引擎出现就立刻判定曲速引擎 (warp drive) 马上会来一样。”布鲁克斯在他最近的一篇文章中写到，完全不需要担心“邪恶的人工智能”(Malevolent AI) ，他说，至少在未来几百年里是如此。

即便超级智能出现的机率和时间要很久，可能不采取措施也是不负责的。加州大学伯克利分校的计算机科学教授司徒特?拉塞尔 (Stuart J. Russell) 与博斯特姆怀有同样的担心，他与库兹维尔在谷歌的同事彼得?诺维格 (Peter Norvig) 合著了 Artificial Intelligence: A Modern Approach 一书，该书二十年来一直作为人工智能的标准教科书。

“有许多本应该是很聪明的公共知识分子现在完全不知道正在发生什么，”拉赛尔告诉我说。他指出人工智能领域的进展在过去十年里非常可观，公众对其的理解还限于摩尔定律 (Moore's Law)，而实际上现今的人工智能技术已经是基础性的，在计算机上使用诸如深度学习这样的技术能够让它们自己增加对这个世界的理解。

考虑到谷歌、Facebook 还有其他公司都在积极主动研发智能的“学习型”机器，他解释说“我认为有一件人类不应该做的事情是，在考虑清楚可能的潜在危险之前，不要尽全力去制造这样一种超级智能机器。这样做有点不明智。”拉塞尔做了一个比较：“这就像合成试验。如果你问一个研究员他在做什么，他们会说在搞容器反应物。如果你想要无限的能源，你最好控制住合成反应。”同样的道理，他说，如果你想要无限的智能技术，你最好搞清楚怎样让计算机和人类需求一致。

博斯特姆的书就是一个研究报告。超级人工智能将会是全能的，它怎么做完全取决于我们 (也就是，工程师们)。和任何一个父母一样，我们必须要给自己的孩子树立一定的价值观。不能是随便什么价值观，而是那些以人类最佳利益为本的价值观。我们基本上是在告诉一个神要如何对待我们。那么如何进行呢？

博斯特姆很大程度上借鉴了思想家利泽?尤德考斯基 (Elizer Yudkowsky) 的一个想法，即“连贯推断意志”(coherent extrapolated volition)——即从所有人当中持续发展 (consensus-derived) 出的一种“最佳自我”(best self)。我们希望人工智能可以带给我们富饶、幸福、满足的生活：治愈背痛的疾病，帮助我们移居火星。考虑到人类从未完全在任何一件事上达成共识，我们将会需要在某一天为自己做决定——为全体人类做最佳的决定。那么我们如何将这些价值观设置成超级智能里的程序呢？怎样的数学可以定义出它们呢？这些都是问题所在，而博斯特姆认为，研究学者们现在应该开始着手解决了。他认为这是“我们这个时代的本质课题”。

对于普通民众来说，现在还没有理由为了恐怖的机器人而担心。我们尚未实现哪怕有一点接近超级智能的技术。不过还要强调的是，世界上许多最大的科技公司都在投入资源，想要让他们的电脑更智能；一种真正的人工智能技术会给这些公司带来难以置信的优势。他们也应该考虑到这项技术潜在的不足，并且想办法避免它们。

在未来生命研究所的网站上，有这样一封公开信。这封信并没有对可能存在的灾难发出警告，而是呼吁有更多研究能够收获人工智能技术的成果“同时避免潜在的问题”。这封信的签名者除了人工智能领域之外的人士比如霍金、马斯克和博斯特姆之外，还有一些著名的计算机科学家 (包括顶级人工智能学者丹米斯?哈撒比斯)。

毕竟，如果这些学者们设计了一种人工智能却又无法实现最佳的人类价值观，那么说明他们还不够聪明，连自己的作品都无法掌控。

