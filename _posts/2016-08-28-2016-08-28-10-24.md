---
layout: post
url: https://www.huxiu.com/article/161745
name: CNET
time: 2016-08-28 10:24
title: 不可杀人戒律过于简单，无人汽车如何应对道德困境？谷歌表示不知道
---
虎嗅注：谷歌工程总监在一次演讲中表示，无人驾驶汽车在面临道德困境时如何抉择，目前尚无答案。

以下内容来自CNET，原标题为《How will driverless cars make life or death choices? Google exec admits he doesn't know》，腾讯译。

据CNET报道，谷歌工程总监Ray Kurzweil最近在奇点大学（Singularity University）演讲时表示，关于无人驾驶汽车在面临道德困境时如何做选择，这个问题目前没有答案。

人们有时会遇到道德困境，从而不得不面对两难选择。在人工智能越来越发达的今天，机器也会遇到同样的问题。

最近，Uber在美国宾夕法尼亚州匹兹堡推出无人驾驶汽车，这是一个令人兴奋的消息。但是，如果无人驾驶汽车面临一种道德困境，它会如何选择，设计者是否已经为它们设计好了应对方式？

例如，假使无人驾驶汽车快要撞上另一辆汽车，那辆车里坐着三个人。它可以转弯闪开，但这样它就会撞上人行道上的三个孩子。

巧合的是，谷歌的工程总监 Ray Kurzweil本周在奇点大学演讲时为这个问题提供了一个答案：我们不知道。

Ray Kurzweil解释说，“不可杀人”的戒律过于简单。他说，如果有人将要炸毁一幢建筑物或一个城市，那么除掉这个人就是符合道德的。

就无人驾驶汽车来说，他认为有必要进行“道德设计”。他说，艾萨克阿西莫夫(Isaac Asimov)的机器人三法则（Three Rules of Robotics ）是一个很好的示范。

机器人不得伤害人类，也不得因为不作为而使人类受到伤害。

机器人必须服从人类的命令，除非这样做违背第一条法则。

在不违背第一条和第二条法则的情况下，机器人必须保护自己。

Ray Kurzweil不知道，不作为——你可以挽救某人的生命却没有这样做——是否等同于杀戮。他承认，在无人驾驶汽车的道德品性方面，他现在完全没有现成的答案。“我要考虑更长的时间。我还没有做过这种分析。”他说。

谷歌的首席工程师Andrew Chatham认为，当无人驾驶汽车面临两难选择时，“答案差不多总是‘踩刹车’。”他承认，这可能并不总是正确的答案。但他表示，如果连踩刹车都不是一种正确的应对，那就是面临极端情形了。

但是，这个世界上不是充满了极端情况吗？

Uber没有回复记者的置评请求，因此目前还不清楚该公司是怎样处理无人驾驶汽车的“道德设计”问题的。

