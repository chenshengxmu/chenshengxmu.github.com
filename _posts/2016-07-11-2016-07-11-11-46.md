---
layout: post
url: https://www.huxiu.com/article/155713
name: 韓宥唯
time: 2016-07-11 11:46
title: 特斯拉“无人驾驶”致命交通事故：车主与测试驾驶员无异，自掏腰包做“小白鼠”？
---
继Tesla Model S发生交通事故导致驾驶员毙命之后，7月6日又发生一起Tesla Model X因为使用Autopilot导致的交通事故。

据悉，这起事故发生在美国宾夕法尼亚州贝德福德市(Bedford)收费公路的出口，车辆在驶离出口时撞上右侧道路护栏，随后反弹至中央隔离带，并发生侧翻。据驾驶人艾伯特·斯卡格里奥内(Albert Scaglione)向警方描述，事发时汽车正处于Autopilot自动驾驶模式。

NHTSA日前宣布，正对Tesla Model S电动汽车展开初步调查，如果经查发现Autopilot自动驾驶功的确存在不安全因素，NHTSA将责令特斯拉召回相应的Model S汽车。

自从推出Autopilot之后，Tesla就一直提醒司机，这是一项测试功能，在开启该功能后，司机仍需要将手放到方向盘上，继续保持对汽车的控制。在Model S发生致命车祸之后，Tesla辩称，那次车祸是Model S系列汽车自动驾驶功能激活使用行驶1.3亿多英里过程中，遇到的第一起致命事故，而全世界平均每6千万英里行程就会发生一起致命车祸。

听起来Tesla的逻辑似乎是，反正全世界每年因为交通事故都要死这么多人，现在我们的Autopilot功能也只不过才死一个而已，而且是开了1.3亿英里之后哦！你们有什么资格说我不安全？

其实仔细想想，这种逻辑似乎也有其一定的道理，听起来也有点耳熟。就好像吸烟的人吐槽室外禁烟区域时，总会提到空气污染一样，反正大家都要呼吸，这城市因为雾霾致死的大有人在，吸烟致死的少得多，你们凭什么说我吸烟危害他人健康？

Tesla为Autopilot辩护的另一个理由是，Autopilot会根据车主驾驶时搜集到的数据，进行分析、学习，不断改进、越变越好，也就是马斯克所说的Fleet Learning功能。这个功能的关键，就是要积累足够多的使用数据，通过Tesla的计算中心与电动车的双向数据沟通，实现Autopilot升级的效果。

但是，需要指出的是，Autopilot仍旧处于“早期测试状态”，通常在这种开发状态下的软件功能，是不会用于量产车上的。也许是为了让车主帮助搜集数据，也许是对自动驾驶功能迫不及待，Tesla不仅将Autopilot推向了大众市场，而且在宣传中极力鼓吹Autopilot的先进。

一方面，Tesla在Autopilot的介绍中反复强调这个功能有多么的方便；另一方面，Tesla又要求车主将双手放在方向盘上，在紧急时刻随时准备控制好汽车。我们来试想一下，这种使用状态，车主既没有办法完全享受Autopilot带来的便利，也没有真正享受纯粹的驾驶乐趣，而且可能还要保持注意力高度集中——因为你不知道什么时候Autopilot就出问题了。

那么这样一来，车主和Autopilot功能的测试驾驶员有什么分别？可能唯一的区别是，Tesla会向测试驾驶员支付工资，并提供其他一系列相关法律要求的待遇保障。而使用Autopilot的车主，不仅要自己买车，自己掏钱升级，使用Autopilot过程中搜集的数据，Tesla也不会付钱，还要自己承担发生事故的风险。像本文初提到的Model S事故，Tesla还要把责任完全推到车主身上。

致命事故的事实证明，Tesla的Autopilot功能是有安全隐患的。Tesla敢于让自掏腰包的车主们去当“小白鼠”，这一点，实在是令人不敢恭维。更令人遗憾的是，大量继续在使用Autopilot的Tesla车主仍旧蒙在鼓里。

