---
layout: post
url: https://www.huxiu.com/article/139023
name: 纽约时报
time: 2016-02-09 19:02
title: 你们把人工智能搞错了！
---
虎嗅注：本文原载于纽约时报，作者：Benjamin H. Bratton，由微信公众号：新智元 编译，编译者有曾辉、Janet Zhao、牟文龙。

像史蒂芬·霍金、伊隆·马斯克、比尔·盖茨这样的专家，最近越发看重它的潜力和威胁。在读完尼克·博斯特伦《超级人工智能》一书后，马斯克大声质问，人工智能是否是”我们现在最大的威胁”。

我们对于人工智能流行的说法被人类伦理所扭曲了。人们对于人工智能的分歧不仅仅体现在它的威胁上，对于强人工智能是否会出现也有不同的看法。一些人认为具备人类相当水平的“强人工智能”（hard A.I.）永远不可能存在，但也有人认为这种趋势将势不可挡。但在很多情况下，这些争论可能偏离了真正的含义：人工智能在存在和思想上，可能和人类自身形式有很大的不同。

简而言之，这种观点表明，一种成熟的人工智能不一定是仿人的智能，或者由我们支配。如果我们以错误的方式去寻找人工智能，它出现的形式可能就会是：难以识别、风险扩大并且延迟收益。

这不仅仅是对于未来的担忧。人工智能早已走出实验室，并且深入日常生活。“弱人工智能”（Soft A.I.），比如苹果的Siri和亚马逊的推荐引擎，以及人工智能基础设施，比如高频算法交易，智能汽车和工业机器人已成为日常生活的一部分，与我们的工具使用、城市发展、经济建设和商品贸易息息相关。

不幸的是，人工智能的主流观点，起码在无数的电影、游戏和书籍中描述的，依然假定那些与人相似的特征（愤怒、嫉妒、困惑、贪婪、骄傲、欲望,更不用说冷漠疏远）是人工智能最重要的部分。这种错误的人类中心主义也许和现在的人工智能研究相去甚远，但这也侧面反映了我们的文化如何看待自我和高级合成认知（advanced syntheticcognition）。

在斯蒂文·斯皮尔伯格2001年的电影《A.I. Artificial Intelligence》中，那个小男孩机器人想要成为真正的男孩，虽然他只有一颗小金属心灵，而天网在电影《Terminator》中则沉迷于人类毁灭。我们不假思索的假定，斯坦利·库布里克和亚瑟·查理斯·克拉克1968年的电影《2001: A Space Odyssey》里的巨石Monoliths是在和人类主人公大卫交流，而不是他宇宙飞船上的人工智能：HAL 9000。

我认为我们应该停止这样的想法：真正的人工智能必须深切考虑到人类，尤其是以人作为它的关注点和动机。也许我们真正害怕的，并非是一台杀死我们的大机器，而是它认为我们无关紧要。这比被视作敌人更加糟糕。

除非我们假设，类人智能代表了所有可能的智能形式（这当然是自欺欺人），否则为什么要根据和我们的相似性来定义先进的人工智能？毕竟“智能”非常难以定义，而人类智能又无法简单地包含所有可能性。即便在实验室它具有实用的价值，但从文化角度，它还是适得其反，是不道德甚至是危险的。

我们不需要如此狭隘和自恋的人工智能观念，所以不能仅仅把我们自身的特性映射到机器的版本中。如果把这种狭隘的观念作为人类和人工智能沟通的基础，这个前提就已经是错误的了。更不用说，历史上不同群体的“第一次接触”，即使是在人类之间，也往往是不愉快的经历

从雷德利·斯科特的《银翼杀手》到斯派克·琼斯的《她》，这些无数的科幻电影在测试人工智能的能力的时候，都要看它是否能被“以人相待”。这种观点从人工智能研究开始一直伴随到现在。这最早可以回溯到1950 年，英国数学家阿兰·图灵发表了论文《计算机器与智能》，那时候他提出了“模仿游戏”测试，也就是我们今天说的“图灵测试”。虽然版本有所不同，但它揭示了我们研究人工智能文化和道德的方法论定义了人工智能本身：无论是好的还是坏的。

最让人熟悉的版本是：提问者向两个隐藏的参赛者提问，一个是人，另一个是计算机。图灵认为，如果提问者不能区分两者的身份，并且计算机能成功假扮成人，那么就成功通过测试。从实践目的来说，计算机不就是“智能”的吗？

计算机需要假装成人以通过人类的测试，而图灵需要隐藏同性恋倾向以通过“直男测试”，这真是有趣的巧合。

遗憾的是，更多的人仅仅“知道”图灵测试，而没有真正阅读过。图灵的文本是非凡、奇妙而令人惊讶的。图灵说他的测试是一种流行客厅游戏的变种：有两个藏在幕后的参赛者，一位女性（参赛者A）和一位男性（参赛者B），他们需要努力说服，让第三个人认为自己是一名女性，通过手写回答问题的方式。为了获胜，一个参赛者必须令人信服的扮演自己，而另一方需要假扮成另一种性别。图灵用计算机取代了玩家A，在字面上你可以理解为，计算机不仅仅要扮演一个人，而且得扮演成女性才能通过测试。

在其他版本的测试中，参赛者B可以是男性，也可以是女性。游戏里可以一个人假装、或者两人假装、抑或两人都不假装，也可以是完全不同的游戏。既然我们让计算机参赛，我们可以让它假扮成女性或男性，这个角色假扮成女性，让询问者分不清男女。也可以玩的更加复杂，计算机假扮成试图假装女人的男人，同时还有一个真的人也在这么做。甚至说，让计算机假扮成为这样的女性，她假扮成试图假装女人的男人。毕竟在现实生活中，这些情况都有可能发生。

莫腾·泰杜姆导演的《模仿游戏》获得了2014年奥斯卡大奖。在那个同性恋被视作犯罪的年代，即便是身为数学家的图灵也得假扮成“直男”。而当他的性倾向暴露时，不得不接受可怕的“化学阉割”治疗。最终，在巨大的身体和精神痛楚下，图灵自杀了。这是历史上荒诞的插曲，当时他对击败希特勒军队的贡献还是一个国家机密。直到最近，图灵才得到了英女王的皇家豁免，然而类似法律下被惩处的其他成千上万的英国男子却未被豁免。

计算机被要求通过测试来证明智力，和图灵被要求假扮成直男来通过测试，这里面有着讽刺的对应，既哗众取宠也极度不公平。

无论是以白人或黑人、男人或女人的身份通过测试，基本上都取决于他人的观察和解释。因为其他人都已经习惯于传统的暗示（种族，性，性别，物种等），所以无论谁想通过测试，都只有和观察者进行共谋。至于人工智能是否愿意这么做，或者仅仅被拖过来完成测试，那就是另一个问题了。无论如何，通过与否更多关乎观众，而非被测试者的表现。

我们最好这样假定，在宇宙中思考是多样化的行为，即便是外星人也会思考，人类并非是特殊的个案。相对于人类教育机器如何思考，人工智能真正的哲学问题是，机器如何教育人类在一个更完整和真实的维度里思考。

过去我们总是根据模拟人类思维的能力来定义人工智能存在，在未来看来，这种想法其实只是一种奇怪的物种偏见。在这种想法下，早期人工智能研究者试图在机器中重建人类思维，但这根本行不通。相反，现代的研究者认为，如果机器能在特定领域里把事情做好，就可以被称作“智能的”，而不是它能在多大程度反映出人类思想。Stuart Russell和PeterNorvig（现任谷歌研究院主任）在他们重要的著作《人工智能》中就指出了，对生物形态的简单模仿并不足以应用于复杂精巧的现代科技：飞机并不以鸟类的方式飞行，我们在测试飞机是否是“真正的”飞行器时，当然也不会去看看鸟类是否会把飞机与同类混淆。既然如此，为什么人们对人工智能采用了这样的判断标准呢？现代务实的人工智能研究并不会把图灵测试作为成功的标准，然而在流行文化中，这种人类中心主义的测试却在长期受到重视。人们对于人工智能的想象大多数还停留在迪士尼电影中会说话的动物这一层次上，而这其实不过是一种幼稚的口技而已。

有人会说：把模仿人类形态作为人工智能的先决条件不够科学，是一种“前哥白尼”时代的观点。那么这种观点真正的问题在哪里呢？如果在未来，我们日常所见的人工智能都具有某种人性，情形会怎么样呢？好的方面是我们会与机器智慧建立一种更为真诚而清醒的关系，而坏的方面是，如果我们对生命体抱有这样的幻想，将会损失更多可能性。有些哲学家已经思考赋予有感情的机器以伦理权利了，但我想要说的不是这个，事实上，我们在思考这些人工智能体的时候，应该寻找更为真实的视角。

马斯克、盖茨和霍金关于人工智能威胁的言论引起了广泛的关注。他们的观点很重要，但是，恐怕大多数读者都误解了他们。如果我们像1942年阿西莫夫“机器人三大定律“一样，寄希望于给机器人编程，禁止它们伤害人类，首先我们就要让机器人能够理解什么是“人类”，以及什么是“伤害”。机器人并不需要做什么恶毒的行为就可以伤害到人类，一个最简单的例子就是：它们只要把人类正常含义的指令以一种机械而极端的方式执行，就足以带来一场灾难。人工智能真正的威胁不在于机械故障或者对于反人类道德的举动，而是在于它们智力强大，却对人类漠不关心。如果我们像以前那样，依据它们与人类的相似性来定义人工智能，并假定它们全心专注于人类事务，我们就更加面临着这方面的风险。

不管想象中的“强人工智能”是否真正会出现，如果我们总是坚持一种我们已经知道其错误的信念，我们将会错失发现和理解人工智能的良机。在1950年的那篇文章中，图灵提到了对他设想的人工智能的很多反驳意见，令人印象深刻的是，他把对人工智能的反对与当年天主教会反对哥白尼天文学相类比。哥白尼的发现使人们放弃了自己处于宇宙中心，具有绝对优越性的错误观点，这种发现是不可估量的巨大成就。这使得人类更清醒地认识世界，把世界实际的状态，而不是从我们这个角度能够观察到的状态，作为思想的基础。图灵把这些反驳意见作为“神学的反对意见”。另一方面，也会有人说，不管图灵测试有多么悠久，把类人智能作为人工智能的先决条件，也同样与“前哥白尼时代”的人类中心主义无异。先进的、不像人类的人工智能的到来，可能会带来一场新的觉醒，使我们对于我们自身、我们所处的环境、以及什么是真正的“智能”有更为清醒的认识。这样我们建立的世界模型就更加接近世界真实的样子，我们对于未来也会更有信心，这总是一件好的事情。

最后，这种想法延续了过去人类与技术的关系，这种关系已经把我们带到了“第六次物种大灭绝”的边缘。按理说，人类中心主义本身并不是来自走向疯狂的技术，而更多地是由于人文主义的遗产，使得我们总是幻想世界是按我们人类的设想，依人类的需要而建立的。这些幻想常常能从现代的意见领袖口中听到，他们向大家布道，勾勒了一个美好的世界，在那里机器是为人的需要和愿望而服务的。如果你真的这样认为，就上网查一下“杀猪机器人”（不要真的这样做），然后我们再来谈谈一个机器完全服从于人的需要的世界是什么样的。

有人或许在想，我们人类社会也经历了从奴隶制度、神权制度到法制社会，所以即便到了2015 年，对机器来说又何尝不可？这种情绪（更精确地说，是这种技术哲学）本质上就是带来人类中心主义困境的原因，如果继续坚持这种观点，我们也很难顺利走向人工智能。人类如果继续坚持这种妄自尊大的习俗，未来将会付出过于高昂的代价。现在，到了我们改变的时候了。

