---
layout: post
url: https://www.huxiu.com/article/162853
name: shidajiyan
time: 2016-09-06 13:59
title: 自动驾驶汽车懂不懂伦理道德？官员表示不相信，工程师表示不知道
---
虎嗅注：谷歌公司宣布自动驾驶汽车掌握新的专利，可以识别警车。无人驾驶系统不断发展，看来能投入使用的日期越来越近，但新的问题也不断被提出，系统对伦理道德将如何设定？美国联邦官员要求政府作出详细规定。

以下部分内容来自《麻省理工科技评论》，原标题为《Top Safety Official Doesn’t Trust Automakers to Teach Ethics to Self-Driving Cars》，作者Andrew Rosenblum，新浪译。

据科技网站DigitalTrends报道，谷歌自动驾驶汽车有一项新专利，能帮助用户不被交警贴罚单。新专利至少能提前感知警车在靠近。

这项专利能根据闪烁的灯光自动探测靠近的车辆，谷歌自动驾驶汽车将学会识别警车发出的蓝色和红色灯光，并做出相应的反应。

随着技术的研发，无人驾驶系统能识别的从交通信号灯、路标到行人，现在再次扩展到警车。

据《麻省理工科技评论》报道，汽车制造商会告诉自动驾驶汽车什么是伦理道德吗？在一场车祸中，自动驾驶汽车能决定什么人被救、什么人应该受伤吗？美国运输安全高价官员对此表示怀疑，他们更相信联邦政府的规定。

自动驾驶的快速进步带来了忧虑，人们担心未来的汽车将不得不做出道德选择，比如，为了防止对车外的人造成严重伤害，汽车是否应该转向，以避免车祸的发生。

美国国家运输安全委员会主席克里斯托佛·哈特(Christopher Hart)是上述人群中的一份子。他表示联邦法规必须为自动驾驶车辆设置基本道德规范，以及必须遵守的安全标准。

哈特说，美国国家公路交通安全管理局(NHTSA)可能需要自动驾驶汽车的设计师像飞机制造商一样，为他们车辆的关键部件内置一套自动防故障系统。

“政府要发挥作用，比方说，'你需要让我看到失败的可能性小于多少，或者你必须向我展示自动防故障装置，确保汽车失控后不会致人死亡，'”哈特说。

哈特还说必须制定规则，规定如何将伦理特权编入代码。他举例说，在与失控的卡车发生致命性碰撞，或迎头撞上护栏或冲入人行道时，自动驾驶汽车都要做出决定。“在我看来，联邦政府要对此作出反应，”哈特说。“那类道德选择将是不可避免的。”

在过去的八个月，美国国家公路交通安全管理局一直在对无人驾驶汽车进行评估，指导意见将在近期公布。该机构尚未对自动驾驶的伦理问题展开讨论。

该机构所评估的自动驾驶汽车来自加利福尼亚等州，使用的是Alphabet和Uber等公司的测试样车。加利福尼亚州要求无人驾驶汽车中必须有一位司机随时准备接手驾驶，至于事故发生时人类需要介入的步骤，一份公司文件报告对此作了详细说明。

瑞安·卡洛(Ryan Calo)是华盛顿大学的机器人学法专家，他对现有理论层面的伦理讨论是否可能转化为实际规则或制度设计表示怀疑。他认为自动汽车不够精密，不足以了解在实际场景中人类将作出的不同反应。

卡洛认为，真正的困惑是我们是否愿意有效地利用自动驾驶汽车，它们既能避免很多事故，偶尔也会造成致命失误。“如果在同一时间遇到一辆购物车和一辆婴儿 车，在食品和人的重要性方面，它无法做出伦理判断，”卡洛说，“因为它拯救过数万人的生命，我们就能说它比人更安全吗？”

帕特里克·林(Patrick Lin)是圣路易斯-奥比斯波市波莫纳加州理工大学的哲学系教授，曾在戴姆勒-奔驰公司下属的非盈利机构研究伦理与自动驾驶，他认为，让汽车作出伦理道德 决定的想法不应该这么快放弃。他说，随着传感器、人工智能和面部识别软件的进步，将有可能让汽车有能力决定挽救一个生命，牺牲另一个。

“最好能在事故实际发生前，积极地尝试预测和管理这些问题，”林说。“这种事情需要立法，否则将毁掉一家企业，或在行业发展史上留下巨大的黑色印记。”

如果有了伦理或其他安全方面的联邦标准，无人驾驶汽车制定决策的过程将更加透明化。林说，汽车制造商普遍希望汽车软件秘不示人，以免被黑客和竞争对手窥探到。他说，“汽车制造商对编程和碰撞优化设计严格保密，这些地球人都知道。”

无独有偶，此前谷歌的工程总监 Ray Kurzweil在演讲时为这个问题提供了一个答案：我们不知道。

Ray Kurzweil解释说，“不可杀人”的戒律过于简单。他说，如果有人将要炸毁一幢建筑物或一个城市，那么除掉这个人就是符合道德的。

就无人驾驶汽车来说，他认为有必要进行“道德设计”。他说，艾萨克阿西莫夫(Isaac Asimov)的机器人三法则（Three Rules of Robotics）是一个很好的示范。我要考虑更长的时间。我还没有做过这种分析。”

谷歌的首席工程师Andrew Chatham认为，当无人驾驶汽车面临两难选择时，“答案差不多总是‘踩刹车’。”他承认，这可能并不总是正确的答案。但他表示，如果连踩刹车都不是一种正确的应对，那就是面临极端情形了。

