---
layout: post
url: https://www.huxiu.com/article/13132
name: 郭昂
time: 2013-04-17 09:29
title: 也谈数据分析这点事
---
昨天看到了caoz写的《数据分析这点事》，非常值得深度，看完后很有感触，也在这里随便写写关于数据分析的个人看法。

首先，在数据分析中我也不敢妄称高手，不会很多分析算法，不会用啥统计工具，只会傻傻的去盯着看。但是我非常喜欢看各种数据，大学时整天看各种硬件评测；研究生阶段看了无数相机、镜头评测；后来是每周琢磨全世界各种游戏机、游戏的销量。工作中也特别喜欢建立各种统计系统，看各种数据，现在公司的所有统计代码都是我自己写的，一般工作每天也会花接近30%的时间研究数据，至少可以算是个不折不扣的数据分析爱好者了。

关于数据分析，caoz已经说的非常好了，我也只能补充一下自己的经验感受了。

1、不管做统计还是看别人的数据，第一步永远是数据获取的可靠性。假如是采样数据的话，一定要看看采样方式，看看可能会存在什么样的误差。如果是自己数据的话，也要看看数据获取本身是否科学，例如统计用户行为一般都用js回调，如果还用apache日志来做统计，结果想来也不会靠谱。

2、获取到数据之后，肯定是需要建立统计，这时候，需要想想，建立什么样的统计信息才能更好的分析产品及用户的特性。很多时候，往往单一特征已经很难去描述，需要综合很多地方来看。例如网页搜索中，往往要看首条CTR、前三条CTR，末次点击等多种因素，并通过很多种不同因素结合做出分析和判断。

3、对数据要抱有怀疑之心，尤其是数据本身与你要达到的结论之间有没有必然的因果关系。举个例子，网页搜索结果如果CTR高一定就是体验好吗？搜索广告的RPM高就一定理想吗？

4、生成同一个数据，往往可以有不同的统计方法，如果选择错误的话，结论往往会大相径庭。例如想分析网站对搜索引擎的依赖性，究竟应该用PV，用Session，还是用UV做统计呢？如果一个用户一天访问多次，某些是来自搜索引擎，某些是主动访问，该如何计算呢？这里面还是有很深的学问。

5、数据中往往会有很多噪声，怎么将这些噪声过滤也很重要。就像投票有投票机，有些spider会执行你的统计js，有些用户会误点，如果没有很好的过滤和处理，会使数据的可靠性大打折扣。

6、理解各种可能会使数据产生波动的原因，并通过不断的分析、验证和排除找到真正原因。例如当发生搜索流量下降，有可能有很多种原因，例如机房网络出故障、竞争对手用某些产品捣乱、上线的代码存在重大不稳定因素、运营商出故障或者拉闸限电等等，这中间每个都有不同的验证方式，需要从服务器日志、基调数据、分区域、用户行为等多个维度去进行跟踪和试验，找到真正可能的核心原因。

对数据进行预估和判断需要一种感觉，这种感觉不是天生的，而需要不断的锻炼和培养。这个过程可能很漫长，一般情况下，需要先看很多数据，培养自己对数据的基本认识，也要分析一些事件中（如周末、节假日、或者故障等）数据的变化。而在产品上线前，先自己锻炼一下预估，然后再通过实际值对自己的预判进行验证和评估。通过这种不断的学习和分析，逐渐培养出自己对数据的领悟。

数据来源于用户，这个很多时候更是需要对人性的研究和分析。就像摆在页面不同位置的广告，CTR一般能达到多少？同样位置，摆广告好还是摆用户产品好？要做某个新产品，CTR能到多少？做互联网的大多是高端用户，很多东西自己是不会用不会点的，但正是这样，需要对用户有非常强的代入感，去换位思考，去分析人性，才能事先避免很多过于乐观的预估，以及无谓的试错。

以上，是自己的一点经验之谈。

欢迎关注微信公众号《搜索引擎探秘》，搜索微信公众号guoang_search

