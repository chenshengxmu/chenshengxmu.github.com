---
layout: post
url: https://www.huxiu.com/article/12449
name: 罗超
time: 2013-04-03 11:30
title: 视觉搜索是移动搜索的未来？
---
选择在这样的日子发布消息，也许百度希望给人以虚虚实实的感觉。在人脸识别方面，百度有这个技术实力。但百度EYE的发布仍然让我觉得诧异——这不像百度的风格。 但笔者关心而且确信的是：百度移动搜索已把视搜索作为一个重点技术方向来搞。 在《展望3B大战之后的搜索变数》一文中，我曾分析过移动搜索与传统搜索的不同——搜索诉求从获取信息变为更加本地化、生活化的实体搜索；搜索方式从WEB网页变为APP；输入方式也因为使用场景的移动性、移动设备的特征和网络环境而发生了巨大变化，从文字输入变为文字、图像、声音、体感、位置的综合输入；输出结果因为移动设备的特征而变得更自然、智能和互动，如语音和图片。另外，广告模式则从“展示广告+超链接”向基于位置的精准营销、O2O和电话拨打广告等方式转变。 上面提到的各种移动搜索技术现在还在探索中。地图、语音搜索相对成熟，而下一个正在爆发的则是视觉搜索。人类既然可以通过声音来驱动设备，又怎会忽略另一个人类与外部环境的核心交互能力——视觉呢？相关科学统计显示，人类有近80%的信息获取来自于双眼。移动设备的摄像头已是标配，视觉搜索极具想象空间，Google Glass就被认为是一个基于视觉搜索的可穿戴设备。 什么是视觉搜索？ 视觉搜索最简单的说法就是“以图搜图”。 图像识别技术已经发展有近30年历史。从最初的指纹识别，到现在随处可见的人脸识别。它们都是将指纹图谱或者人脸图片转换提取出特征，与设备中存储的已有特征照片进行比对。如果相似度达到某个阈值，则匹配成功，这被广泛应用于日常考勤、安保、电脑解锁中。网易近期还推出了“人脸邮箱”就是这样的旧技术搭上新应用。 不过，上面说的图像识别技术还只是一种一对一匹配技术，远远还没发展到搜索的程度，如同雅虎时代的“网址索引”阶段，而视觉搜索则到了Google和百度为代表的第二代搜索的阶段。与简单的匹配不同，视觉搜索是基于算法和数据的。首先需要搜索引擎拥有大量图片库，然后提取特征值，聚类建索引。在用户搜索时，将搜索照片进行解析，去繁存真，检索并根据相关性排序，返回结果。这个结果可能是一堆图片，也可能是与图片相关，结合用户特征和搜索场景的相关信息。这个过程与现在的主流搜索引擎的过程比较接近。 这个技术的应用场景在哪里？如果够智能，它可以成为一双帮你变得更聪明的眼睛。思维过程也是到大脑的记忆存储区域去匹配相似场景，最后与一些信息概念映射，并作出行动反馈。如果你看到一个人，似曾相识但就想不起来名字，这个思维过程就可以被比作整个视觉搜索的慢动作了。这时候或许视觉搜索可以帮你。不过，这得你大脑存储的记忆全部数字化，能传递到电脑才行。 从全球范围看，在视觉搜索技术的探索方面，走在前面的当然是Google。Google在2009年分别推出网页版Google相似图片搜索和Google Goggles，后者是一款安卓版APP，可以拍照并搜索相似照片。2010年，Google特意收购英国视觉搜索公司Plink，以加强Goggles。Google这套东西除了相似图片搜索技术应用于其购物搜索外，其他的并未带来商业价值。直到Google Glass的出现才让其积累多年的视觉搜索技术有了爆发的空间。 百度的发力也并不算晚，它在2010年推出百度识图搜索（shitu.baidu.com)开始涉水视觉搜索的。不过当时因为使用场景有限，这款产品并未被大众熟知。更多是满足了一种新鲜感。 即便如此，百度仍然投入了大量资源来研究视觉搜索。这样的判断应该与技术出身的李彦宏喜欢研究技术趋势有关。两年前李彦宏就宣称互联网“读图时代”到来，在去年的KDD（知识发现世界年会）上，他提出的待解9大技术问题中，“基于内容的的视觉搜索”排在第三位。 李彦宏在去年底的百度年会上宣布了百度2012年的压轴之作：全世界首个“全网人脸搜索”。这是一款通过用户上传照片，就能在互联网上找到相似照片的产品。图像识别技术应用于全网搜索后，以图搜图的准确率一下子从20%提升到80%。正是应了那句话，技术积累的先发投入，往往会体现在产品的后来居上。 这款产品的识别准确率依赖于被搜索的人脸在网上的照片数量：百度的大规模并行计算机器群会将爬取的照片（不会抓取未开放的私人相册）进行特征提取和聚类。在这个过程中，会用机器学习算法对人的面部表情喜怒哀乐进行识别学习。照片越多，机器学的材料越多，进而识别率也就越高。据说普通照片识别率已达90%。明星甚至高达99%，百度的大数据优势有关系。 视觉搜索于“移动”的意义 百度愿意为这个目前尚处研究阶段的视觉搜索技术倾注资源，可以解释为一切都是为了移动互联网布局。去年在其移动互联网策略和成果不明朗的情况下，外界甚至猜测百度在移动互联网时代是不是已经失去了昔日位置。不过今年又逐渐明朗起来，地图、语音、APP及APP内搜索，后发而至。尤其是现在百度在视觉搜索方面的成果，更让我确信百度的下一个移动互联网发力点将是移动视觉搜索。 在移动互联网上视觉搜索的空间甚至比语音搜索还要大。语音搜索的瓶颈除了识别率赶不上图片识别外，对使用者的说话语气、语速、口音等要求颇高。最大的问题是使用场景的局限性：跟手机说话会干扰周围的人；容易会被周围的环境干扰。也就是说，语音搜索适合相对独立和安静的空间使用。 而对于移动场景下对“线下实体”的搜索，比如商铺、商品、餐厅、菜品、图书、环境、招牌、景点甚至地铁对面的美女。这些场景显然不是“安静”和“独立”的，视觉搜索可以避开上述问题。 视觉搜索除了能与移动设备的摄录能力天然结合外，它也很好地满足线下的搜索场景和诉求。条形码和二维码在这方面开了个先河，除了商品，你可以对着海报、朋友的名片、甚至芒果台节目上的二维码“扫一扫”，然后匹配信息并建立联系。 不过条形码、二维码也只是在某些特定类型的物品上。我们的世界不可能会充满二维码，它天生是给机器读的。而视觉搜索呢？人眼所见即所得。只要人类能看到的，它都可以帮你进行抓取并搜索。 未来的视觉搜索是什么样呢？类Google Glass的智能眼镜的普及会成为一个里程碑。在这之后，无论是物体、图片、二维码，对视觉搜索引擎来说，都是将真实的物理世界信息映射为互联网信息的方式。摄像头是移动互联网时代的入口，就像PC时代的搜索框一样。这是Google和百度等搜索巨头都对视觉搜索投入大量资源的原因——流量入口是搜索引擎的生命之源。 现实远非完美 视觉搜索未来很丰满，但是现实仍有些残酷。如同李彦宏在去年KDD大会提出来的，视觉搜索仍然是待解的技术难题。百度人脸搜索之所以能取得成功，除了百度有海量的人脸照片外，还与人脸是常规图像有关系。技术上，业界包括谷歌和百度在探索方面既有进展也有挑战：在对平面或刚体（书籍、CD、建筑物、油画、明星照片等）的搜索方面，召回率已超过90%；但对“非刚体”图像的识别，就对机器算法有更高的要求（比如动物）。 在常规图像上，视觉搜索的识别率肯定会低于二维码和条形码扫描。不过，如果视觉搜索可以实现百度人脸搜索那样的精度甚至更高，以及随着4G到来WIFI覆盖加强，网络环境变得更好，当李彦宏说的2.9秒搜索时长变为0.1秒后，视觉搜索就将迎来大规模应用。 视觉搜索被诟病的还有交互的自然性，所以有戴着Google眼镜去酒店被打的，扎克伯克也说带着它很囧。Siri是在和我们对话，而现在的视觉搜索仍然是“我们使用这款设备拍照并进行搜索，来完成任务”的过程。Google Glass的出现让我们的眼睛多了一个视觉搜索功能，以前我们看到环境搜索大脑，现在我们看到环境搜索大脑+云端信息。 视觉搜索仍然存在很多瓶颈以及风险。隐私问题，以及人类自我的问题。笔者《今天不矫情，明天成贱人》提出过科技越进步，人类越暴露的观点。你无法判断你对面的人是否在用他的第三只眼睛拍摄记录你，以及搜索你。除了隐私外，越来越聪明的技术和设备，与人类自身的位置如何协调？我们是不是终有一天会被设备奴役？当这“第三只眼”真正进化成隐形眼镜，就是我们的身体开始被设备奴役的开端了。你不用担心对别人造成干扰了，或者说是你永远不用担心别人知道你的干扰。 作者博客，微博：IMSuperLo，微信：SuperSofter

选择在这样的日子发布消息，也许百度希望给人以虚虚实实的感觉。在人脸识别方面，百度有这个技术实力。但百度EYE的发布仍然让我觉得诧异——这不像百度的风格。

在《展望3B大战之后的搜索变数》一文中，我曾分析过移动搜索与传统搜索的不同——搜索诉求从获取信息变为更加本地化、生活化的实体搜索；搜索方式从WEB网页变为APP；输入方式也因为使用场景的移动性、移动设备的特征和网络环境而发生了巨大变化，从文字输入变为文字、图像、声音、体感、位置的综合输入；输出结果因为移动设备的特征而变得更自然、智能和互动，如语音和图片。另外，广告模式则从“展示广告+超链接”向基于位置的精准营销、O2O和电话拨打广告等方式转变。

上面提到的各种移动搜索技术现在还在探索中。地图、语音搜索相对成熟，而下一个正在爆发的则是视觉搜索。人类既然可以通过声音来驱动设备，又怎会忽略另一个人类与外部环境的核心交互能力——视觉呢？相关科学统计显示，人类有近80%的信息获取来自于双眼。移动设备的摄像头已是标配，视觉搜索极具想象空间，Google Glass就被认为是一个基于视觉搜索的可穿戴设备。

图像识别技术已经发展有近30年历史。从最初的指纹识别，到现在随处可见的人脸识别。它们都是将指纹图谱或者人脸图片转换提取出特征，与设备中存储的已有特征照片进行比对。如果相似度达到某个阈值，则匹配成功，这被广泛应用于日常考勤、安保、电脑解锁中。网易近期还推出了“人脸邮箱”就是这样的旧技术搭上新应用。

不过，上面说的图像识别技术还只是一种一对一匹配技术，远远还没发展到搜索的程度，如同雅虎时代的“网址索引”阶段，而视觉搜索则到了Google和百度为代表的第二代搜索的阶段。与简单的匹配不同，视觉搜索是基于算法和数据的。首先需要搜索引擎拥有大量图片库，然后提取特征值，聚类建索引。在用户搜索时，将搜索照片进行解析，去繁存真，检索并根据相关性排序，返回结果。这个结果可能是一堆图片，也可能是与图片相关，结合用户特征和搜索场景的相关信息。这个过程与现在的主流搜索引擎的过程比较接近。

这个技术的应用场景在哪里？如果够智能，它可以成为一双帮你变得更聪明的眼睛。思维过程也是到大脑的记忆存储区域去匹配相似场景，最后与一些信息概念映射，并作出行动反馈。如果你看到一个人，似曾相识但就想不起来名字，这个思维过程就可以被比作整个视觉搜索的慢动作了。这时候或许视觉搜索可以帮你。不过，这得你大脑存储的记忆全部数字化，能传递到电脑才行。

从全球范围看，在视觉搜索技术的探索方面，走在前面的当然是Google。Google在2009年分别推出网页版Google相似图片搜索和Google Goggles，后者是一款安卓版APP，可以拍照并搜索相似照片。2010年，Google特意收购英国视觉搜索公司Plink，以加强Goggles。Google这套东西除了相似图片搜索技术应用于其购物搜索外，其他的并未带来商业价值。直到Google Glass的出现才让其积累多年的视觉搜索技术有了爆发的空间。

百度的发力也并不算晚，它在2010年推出百度识图搜索（shitu.baidu.com)开始涉水视觉搜索的。不过当时因为使用场景有限，这款产品并未被大众熟知。更多是满足了一种新鲜感。

即便如此，百度仍然投入了大量资源来研究视觉搜索。这样的判断应该与技术出身的李彦宏喜欢研究技术趋势有关。两年前李彦宏就宣称互联网“读图时代”到来，在去年的KDD（知识发现世界年会）上，他提出的待解9大技术问题中，“基于内容的的视觉搜索”排在第三位。

李彦宏在去年底的百度年会上宣布了百度2012年的压轴之作：全世界首个“全网人脸搜索”。这是一款通过用户上传照片，就能在互联网上找到相似照片的产品。图像识别技术应用于全网搜索后，以图搜图的准确率一下子从20%提升到80%。正是应了那句话，技术积累的先发投入，往往会体现在产品的后来居上。

这款产品的识别准确率依赖于被搜索的人脸在网上的照片数量：百度的大规模并行计算机器群会将爬取的照片（不会抓取未开放的私人相册）进行特征提取和聚类。在这个过程中，会用机器学习算法对人的面部表情喜怒哀乐进行识别学习。照片越多，机器学的材料越多，进而识别率也就越高。据说普通照片识别率已达90%。明星甚至高达99%，百度的大数据优势有关系。

百度愿意为这个目前尚处研究阶段的视觉搜索技术倾注资源，可以解释为一切都是为了移动互联网布局。去年在其移动互联网策略和成果不明朗的情况下，外界甚至猜测百度在移动互联网时代是不是已经失去了昔日位置。不过今年又逐渐明朗起来，地图、语音、APP及APP内搜索，后发而至。尤其是现在百度在视觉搜索方面的成果，更让我确信百度的下一个移动互联网发力点将是移动视觉搜索。

在移动互联网上视觉搜索的空间甚至比语音搜索还要大。语音搜索的瓶颈除了识别率赶不上图片识别外，对使用者的说话语气、语速、口音等要求颇高。最大的问题是使用场景的局限性：跟手机说话会干扰周围的人；容易会被周围的环境干扰。也就是说，语音搜索适合相对独立和安静的空间使用。

而对于移动场景下对“线下实体”的搜索，比如商铺、商品、餐厅、菜品、图书、环境、招牌、景点甚至地铁对面的美女。这些场景显然不是“安静”和“独立”的，视觉搜索可以避开上述问题。

视觉搜索除了能与移动设备的摄录能力天然结合外，它也很好地满足线下的搜索场景和诉求。条形码和二维码在这方面开了个先河，除了商品，你可以对着海报、朋友的名片、甚至芒果台节目上的二维码“扫一扫”，然后匹配信息并建立联系。

不过条形码、二维码也只是在某些特定类型的物品上。我们的世界不可能会充满二维码，它天生是给机器读的。而视觉搜索呢？人眼所见即所得。只要人类能看到的，它都可以帮你进行抓取并搜索。

未来的视觉搜索是什么样呢？类Google Glass的智能眼镜的普及会成为一个里程碑。在这之后，无论是物体、图片、二维码，对视觉搜索引擎来说，都是将真实的物理世界信息映射为互联网信息的方式。摄像头是移动互联网时代的入口，就像PC时代的搜索框一样。这是Google和百度等搜索巨头都对视觉搜索投入大量资源的原因——流量入口是搜索引擎的生命之源。

视觉搜索未来很丰满，但是现实仍有些残酷。如同李彦宏在去年KDD大会提出来的，视觉搜索仍然是待解的技术难题。百度人脸搜索之所以能取得成功，除了百度有海量的人脸照片外，还与人脸是常规图像有关系。技术上，业界包括谷歌和百度在探索方面既有进展也有挑战：在对平面或刚体（书籍、CD、建筑物、油画、明星照片等）的搜索方面，召回率已超过90%；但对“非刚体”图像的识别，就对机器算法有更高的要求（比如动物）。

在常规图像上，视觉搜索的识别率肯定会低于二维码和条形码扫描。不过，如果视觉搜索可以实现百度人脸搜索那样的精度甚至更高，以及随着4G到来WIFI覆盖加强，网络环境变得更好，当李彦宏说的2.9秒搜索时长变为0.1秒后，视觉搜索就将迎来大规模应用。

视觉搜索被诟病的还有交互的自然性，所以有戴着Google眼镜去酒店被打的，扎克伯克也说带着它很囧。Siri是在和我们对话，而现在的视觉搜索仍然是“我们使用这款设备拍照并进行搜索，来完成任务”的过程。Google Glass的出现让我们的眼睛多了一个视觉搜索功能，以前我们看到环境搜索大脑，现在我们看到环境搜索大脑+云端信息。

视觉搜索仍然存在很多瓶颈以及风险。隐私问题，以及人类自我的问题。笔者《今天不矫情，明天成贱人》提出过科技越进步，人类越暴露的观点。你无法判断你对面的人是否在用他的第三只眼睛拍摄记录你，以及搜索你。除了隐私外，越来越聪明的技术和设备，与人类自身的位置如何协调？我们是不是终有一天会被设备奴役？当这“第三只眼”真正进化成隐形眼镜，就是我们的身体开始被设备奴役的开端了。你不用担心对别人造成干扰了，或者说是你永远不用担心别人知道你的干扰。

作者博客，微博：IMSuperLo，微信：SuperSofter

