---
layout: post
url: https://www.huxiu.com/article/115903
name: Wired
time: 2015-05-24 15:32
title: 神经元人工智能网络已开始超越人类，但计算机仍有许多不确定性
---
虎嗅注：今年一月份，来自加州大学伯克利分校计算机科学家拉塞尔 (Stuart Russell) 起草了致全体人工智能研究员的公开信，并第一个在上面签名。拉塞尔呼吁研究者不能只注重让人工智能变得更强大，同样要保证其健康性和有益性：AI 必须遵从人类的意愿，不能胡作非为。

原文来自 Wired，本文转自网易科技，《人工智能先驱为何会担忧人工智能？》。

公开信发表后，已有数千人在上面签名。其中不乏来自谷歌、Facebook、微软等顶尖人工智能研究机构的科学家。同时来自全世界的物理学家、哲学家也在上面留下了自己的名字。

拉塞尔表示目前的AI技术已经有了长足的进步，神经元算法带来的改善不容小视。这些智能算法被应用在人脸识别系统、智能手机助理系统以及谷歌自动驾驶汽车中。甚至，《自然》杂志的一篇报道称一个模拟神经元人工智能网络在一款Atari公司的游戏中的表现已经超过了人类，而这个系统的输入仅仅是电脑屏幕上显示的内容和一个“得到尽可能高的分数”的目标。没有任何预设的程序，这个智能网络懂得分辨屏幕上的外星人、子弹，会在合适的时机进行左移、右移。 让我们来看看拉塞尔如何评价这一革命性技术。 你为什么坚持人工智能研究必须以可证实对人类有益为前提？ 我认为这是一个错误的问题，因为“人类价值”不能被“证实”。当然，人类价值本身也没有准确的定义，谁又知道人类为什么存在呢，可能这永远都是个迷。但考虑到我们人类的行为的意义，你会希望机器人至少能体会到其中的大部分精髓。人工智能可能不能完全理解我们的所作所为，但它们至少要和我们站在同一战线上，有着共同的基本原则。换句话说，它们不能成为我们的绊脚石甚至伤害我们。 你打算怎么实现这一点？ 我现在正在这方面努力。目前我觉得一种名为“逆强化学习”的技术可以派上用场。平常的学习原理很简单，基于你的表现好坏，你会得到奖励或者惩罚，你的目标也很明确，就是想方设法获得尽可能多的奖励。Atari的游戏就是一个这样的典型的系统。逆向学习则是完全相反的过程，你首先得到结果，然后你去思考什么样的行为最可能带来这样的结果。比如，你的机器人看到你早上艰难的从床上爬起来，冲了一杯咖啡，在一个嗡嗡作响的箱子里加热了点煎饼，而且在吃这些东西时你脸上浮现出了愉快的深情，那么它的人工智能就会告诉它：人早上喝咖啡是好的。 逆强化学习有着海量的资料可以使用，无论是书籍、电影还是网络，上面有着成千上万的人类活动记录，智能体可以从中感受到人类追求的基本价值和遵循的基本原则。 你的研究生涯主要关注了理解人工智能是什么，并认为这是实现人工智能的前提。那么你目前有什么收获呢？ 在八十年代的研究中我开始思考理性决策的问题，后来我发现这是一个不可能完成的任务。如果你是理性的，你会判断自己目前的状况、可选择做法、每种做法带来的结果，但是又有哪一种做法是百分之百确保得到想要的结果的呢？世界上的事情变化多的让人眼花缭乱，没有那么多事是确定的。理性行为的定义就要求你的能力盖过整个未来和宇宙，换句话说，它在计算上是不可能的。所以我换了思路：那么人类是怎样做决定的呢？ 人类怎么做的？ 人类的大脑是一部效率惊人的概率运算机器。它的诀窍不是准确掌握每一条信息，而是对未来有一个大概的预测，并推测最可能带来好结果的做法。拿下棋来说，如果是理性决策的人，他就只会走那些可以将军的棋子。现实中没有人这么下棋，人们不会考虑十几步之后的事情，他们会考虑几个可能的走法，看哪一种最可能带来优势。人一生大约会做20万亿的动作，做一次演讲会有13亿个动作，理性决策要求你预测13亿个动作后的准确状况，这太疯狂了。我们从不会想“我要先迈左脚再动右脚，再打开门……”而是想“我该去做演讲了”。 你可以证明人工智能系统不会重写自己的软件，覆盖人类预设的目标吗？ 计算机程序有着许多不确定性。阿兰图灵曾指出一个计算机程序不可能判断另一个程序是陷入了无限循环还是最终会产生输出。因此，如果你有一个可以重写自身的程序，你就有了一个矛盾，你不能证明这个新程序是否具有某些性质，这个程序也不知道自己写了一个什么。所以，问题不是“AI是否会重写自己”而是“AI写出的程序会对我们有怎样的影响”。我们目前对人工智能的设计能力所知甚少。 目前有什么很有前景的研究领域吗？ 最近出现了一种叫做“网络现实系统”的研究领域，它们的研究内容是计算机与现实世界相联，让电脑通过网络控制机器手臂等等。许多电影中出现了人工智能掌控交通的剧情，也是该领域的研究内容。另外，空中交通管制也是其应用的一种。

