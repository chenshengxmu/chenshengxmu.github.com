---
layout: post
url: https://www.huxiu.com/article/130618
name: 李智勇SZ
time: 2015-11-09 08:35
title: 从社交网络的视角来看社会形态演变，为什么封杀人工智能是不对的？
---
本文头图经海洛创意授权，未经允许，不得转载。

这几年互联网巨头不约而同的在人工智能上加大投入，最近就连此前对此无动于衷的苹果也开始发力。虽然我们仍然不能精确预计究竟什么时候我们会迎来真的强人工智能，但商业巨头的竞赛至少在暗示着这个地方已经面临着一种用户可感知层面的突破。这篇文章不会探讨商业，而是会探讨下一旦人工智能领域真的产生某种突破，那究竟会给我们的生活带来怎样的影响。

现在各种电子产品越来越多，笔记本、Pad、手机、手表等，这些产品从外观和功用来看无疑差异很大，但实际上它们的基本架构和原理却是相同的，一般来讲这种架构会被叫冯·诺依曼结构。如果回溯这种结构的最初目的，那就会发现计算机还真是用来做计算的，虽然它现在可以用来干从炒股到订饭的一切事情，但在大概三十年前，它的主要存在目的就是用来做计算，相当于是大号的算盘。

人的理性思维先天是有做算术的潜质的，所以丈量土地这样的实际需要一出现，各个文明几乎都会出现数字。人的思维这部分功用的最大特征是容易规则化，容易规则化那就意味着比较容易做量上的伸缩（比如计算速度），计算机最开始就承担了这个使命。

虽然现在各种软件App五花八门，但基本上没摆脱最原始的设定，它始终做的是理性思维在量上的伸缩，只不过参数越来越多，人机交互的方式越来越形象可以并行，可以处理海量的数据，编写的语言越来越容易等。这类程序虽然偶尔也会有缺陷，但主要原因往往是“如果A条件满足，那么做B”这样的条件嵌套过多，再加上并行处理，导致其内部的分支变的极为庞大导致的。不管怎么样，这样的程序骨子里是可控的，主要是随着规模的增加其控制难度在增加。

但机器人需要的完全不一样的程序，这种程序骨子里是不可控的，其结果其实是种概率。比如说你训练一个程序去识别图片里的猫，当这个程序碰到下一张具体的图片时，其实你没法控制它到底把它识别成什么，所以会有把黑人识别成大猩猩的情形出现。

这里面很有意思的事情是，前一类程序的大发展为后一类有独立智能的程序的发展提供了充分的条件。没有大数据和云提供的高计算能力，深度学习这样的技术在语音、图像识别这样的领域就很难取得眼下这种显著进展。图像识别的技术在在特定领域比如国家领导人的形象识别甚至可以达到99%的准确率，这是在十几年前不可想象的。

或许我们可以这么看，技术上也有从0到1，从1到100的过程。图灵、冯·诺伊曼完成了把理性思维用计算机表现的从0到1的过程，接下来很多年里工程上人们创造了摩尔定律，迅速的把1推向了100。

现在人工智能则还是在从0到1的过程之中，但这种过度要充分依赖于前一类技术从1到100所带来的结果。对于人工智能而言，眼下的关键是什么时候它才可能进入从1到100的快速发展通道，毕竟当前在NLP（Neuro-Linguistic Programming神经语言程序学）上这种进展还不是特别的大。单只深度学习似乎还不足以承载这种从0到1的变化，但有一定可以确定的是，人工智能上从1到100的过程要远快于前一种软件。

虽然我们很难准确预计什么时候人工智能可以完成从0到1的飞跃，但这种变化会发生是不用特别怀疑的。那我们就不妨跳过发展细节来想象下如果GNR（尤其是人工智能）确实取得了突破，那我们的世界会变成什么样？

人类如果不特别虚伪的话，那我们就必须直接承认我们创造人工智能的根本目的其实是——获得一个忠诚不二而又神通广大的仆人，中间也许会夹杂部分情感需求，比如电影《人工智能》里所展现的爱意。但后者是次要的，就和很多小朋友也喜欢毛绒玩具，但它是可以被抛弃而没有心理负担的。骨子里我们并不需想制造出一种完全和我们平等的生灵出来，那样的话直接生养众多或者克隆就够了，当然我们也更不想制造出一种超然的生灵来凌驾人类之上。

从这个角度看，强人工智能也可以分为两个阶段：

第二阶段是产生本我意识的阶段。这个时候它可能会开始追问自己的存在价值。这时候人也许还在想象力和判断力上保留优势，但在其它方面会逊于这种人造的生命体。

这背后隐含了人机的三种关系和状态。最理想的是主仆关系，人工智能是人类的半复制品。

1、理想状态是机器人、人工智能服务于人类，这可以认为是一种人类中心论。

2、较差的是机器人产生意识，这时候就有人机道德问题，人机应该生存在怎样一种秩序之下。而这个时候一个分支就是人机可能需要融合，这种情形其实应该努力防止，因为只要我们相信思维天生是外倾并寻求自由的，那人机间就很可能发生冲突。因为这时候你并不能要求它只存在于你设定的范围之内，它的本我意识会让它有自己的选择，比如像《机械姬》里描述的那样它会选择努力走出去。人类花了近万年来调和人与人之间的矛盾，最终才在200年前认识到自由平等是更好的选择，如果进行到这一种状态，那人机的平等则需要比这更快的得到共识。

3、最糟糕的情形就是制造出超人。这时候这种超人一定会架在人类上面，人要么转化为这种超人，要么毁灭。

如果走到第二种情形，那就很容易演化成第三种情形。必须一提的是如果王东岳先生递弱代偿成立，那最后这可能性其实就不太应该，因为这会造就一种在各方面都趋于完美的物种。

那是不是说现在应该封杀人工智能？答案显然不是。此前的工业革命确实带来了世界级的大战，但也让我们终于不用匍匐在土地上为食物发愁，平均寿命得以延长等。人工智能虽然风险暗藏，但其实也带来了让人类文明进入黄金时代的机会。何况在一个多元的世界里，个人虽然可以选择用不用，但并没有选择不发展的权利。所以关键的问题不是看到风险，而是看到风险后应该如何前行。

历史学家习惯更详细的划分各种社会类型，比如农业文明、工商业文明，农业文明还可以进一步划分为封建社会、四民社会（钱穆认为秦汉以后中国的社会结构可以称之为四民社会与封建无关），但不管如何划分总要处理人与人的关系问题。

从这个角度看人类的金字塔结构亘古未变，而从这角度看人工智能所能扮演的角色也就更加清楚，它相当于在金字塔的最下层塞上一层。这是人类的终极解放，人类可以把自己不愿意做的事情委托给人工智能，而专注在自己想做的事情上。

我们知道人与人之间的关联其实也是一种网络，而以网络的形态而言其实有两种典型的形态：一种是去中心化的网络，一种则是中心化的网络。从社交网络上可以特别直观的理解我们现在的社会形态，少数人是中央节点，多数人则相对普通。造成这类状态的原因在于，随着生活社会化程度的加深，每个人对外的依赖就会越来越多，工作、医疗、教育、购物、出行等都让人对外部产生某种依赖。

马克思当年也用这视角来审视资本主义，它发现工人要想做事情必须完全依赖于生产资料。在大工业生产时代确实如此，个体的工人对原料、机器、供应链的依赖无比强烈，所以如果工人不联合起来，根本就没有和掌握生产资料者的阶层进行议价。因此而产生的对抗其激烈程度历经百年终于趋于温和。

这一切关联都内置某种分配规则，最终就把人束缚在其中，最终就会形成这种中心化的网络。与此相对应的是热带小岛上可以天然获得足够食物的土著，它也许关注爱情，但却并不没被套在这样一种复杂的网络之中，所以他是足够独立的。所以说现代文明即给人带来了更大的自由，但也给人以更多束缚。人们渴望休闲而努力工作创造更多财富，但反过来工作本身却占据越来越多的时间，让休闲并不可得。但不管怎么想，大多人完全没有脱离这种网络的可能性。

之所以说这个，是因为人工智能给人类带来了一个既可以与现代文明高度融合又可以保持独立的机会。理论上讲人工智能可以全能的，它可以照看小孩、完成孩子的教育、诊断你的疾病、种地、做饭、驾车。当然它无法创造空间、物质。所以这时候唯一的关键点是能源与人口的比例，人心里是否有野望。也正为个人可以不予外求，就生活的很好，中心节点将大幅失去存在价值。这意味着人与人会更加的平等。

这里的唯一问题在于掌握人工智能者就是最大的节点，所以如果这里的财富属于个人，那未来的财富聚集程度肯定比80/20所体现的还要夸张。

第一类如果从1995年算起，那第一类软件吞噬世界的核心时间其实也不过就用了20年，即使从1936年图灵提出图灵机算起，那也不过用了80年。所以上述所说的变化绝非遥不可及的变化，至少90后是非常可能在有生之年感受的到。人工智能究竟会带给我们怎样一个世界其实是一个可以开始思考的问题。

