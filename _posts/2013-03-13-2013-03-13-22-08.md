---
layout: post
url: https://www.huxiu.com/article/11407
name: 虎嗅
time: 2013-03-13 22:08
title: 在Twitter谷歌IBM那里，人工是如何干预算法、调教机器的
---
本文节选自《纽约时报》，由新浪科技翻译：

尽管计算机算法正变得越来越强 大、快速和精准，但始终还是只能理解文字字面的意思，任何上下文的引申义和细微的差异往往会成为绊脚石。即便已经非常强大，但计算机算法还是无法破译人类 语言的模糊性和推理的奥秘。但现在人们的要求已经大大提高，希望身边的设备更能像一个人一样提供信息。

因此，当编程专家们仍然“按部就班” 地编写计算机代码时，更多的人需要加入进来做些更微妙的贡献。为了满足用户更深层次的需求，人们不得不对计算机算法的工作进行评价、编辑或校正。例如，人 们收集网络上的资料库，检查和验证它们，然后把它们编辑成能够响应计算机请求的表单，将答案呈现在用户面前。在这一过程中，人类对信息做了解释和调整，使 之能够同时被机器和用户所理解。

我们不妨把这种行为称为新兴的机械与人工协作模式，诸如苹果语音助手Siri和IBM的沃森超级计算机在内的问答技术都属于这一范畴。在这类技术中，单纯的计算机算法是无法胜任的。

以 Twitter为例，该服务就动用了很多被称为“裁判员”的合约工，来理解那些搜索频率突然飙升的词汇的语义和上下文意思。例如，当米特·罗姆尼在去年的总统竞选中谈及削减政府对公众广播的预算时提到了“大鸟”(Big Bird)一词，一时间包含该词的消息在Twitter上炸开了锅。很快，Twitter的人工裁判就判断出这里的“大鸟”应该是一个政治评论，而非通常 意义上的意思，从而对算法做出调整——当人们搜索“大鸟”时，保证跳出来的是罗姆尼谈论的“大鸟”及其相关消息。

在这个实例中，只有人类才 能快速而准确地理解这样的词汇及其背后的相关信息，软件是无法在较短时间内完成的。同时，裁判们会立即把它加入Twitter的搜索算法，确保显示结果与 人们期望的一致。Twitter的两位工程师在博客中写道：“在这类事件中，人工才是系统的核心。”

即 便是在非常崇尚算法和工程的谷歌，人工对搜索结果的贡献也越来越多。几个月前，谷歌开始在知名的地点或人物的搜索结果右边栏显示摘要信息，譬如当你搜索 “奥巴马”或“纽约”时，旁边就会出现简单的介绍。这些摘要介绍信息一般来自维基百科和其它数据库，经过人工编辑而成。这样一来，当谷歌的搜索算法检测到 这些特殊词汇是就会调用整理好的介绍信息，而不是简单的显示连接到其它站点的链接。

在谷歌负责搜索质量的工程总监斯科特·霍夫曼(Scott Huffman)表示：“我们的思路有了转变，部分搜索结果加入了人工策划的结果。”

除了内容策划人员，还有其他人在帮助谷歌开发调整搜索算法，以应对每月超过1000亿次的搜索请求。他们通常被成为“评估员”。霍夫曼表示：“我们的工程师开发了搜索算法，但需要评估员帮助测试某一改动是否能够提升搜索质量。”

23 岁的凯瑟琳·杨(Katherine Young)是一位谷歌搜索的评估员，她是谷歌签的合同工，目前还在上大学。杨的工作是检测和调整模糊的搜索结果和排序问题。譬如，针对“国王手里握的是什么”，她需要审核现有的搜索结果，给出合理的搜索结果和先后排序。譬如，一个包含“国王手握权杖”的网页会被作为合理的参考答案放在第一位。

杨表示：“评估不是非黑即白的选择，有时你不得不将自己置于用户的角色，然后找出合理的结果及排序。”

IBM的超级问答计算机沃森经过了很长时间的训练，试图为医生诊断提供专业的答案。不过即便如此，它也需要人工的介入。

作 为“助理医生”，沃森掌握了多种医疗书籍里面的知识。此外，沃森还会接受来自医学院的临床医生们各种询问，不断修正自己的知识库。譬如，沃森可能会被问到 这样的问题，“什么样的神经系统疾病是禁忌使用安非他酮的？”沃森的软件系统数据库里可能包含了安非他酮这种抗抑郁剂，但它可能会不明白禁忌是什么意思。 这时就需要人工的介入，告诉机器禁忌就是不能使用的意思，然后沃森才可能给出“癫痫症不能使用安非他酮”这样的答案。

IBM科学家埃里克·布朗(Eric Brown)称：“我们借助医学专家帮助沃森学习，使它变得越来越聪明。”

