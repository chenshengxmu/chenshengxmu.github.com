---
layout: post
url: https://www.huxiu.com/article/45670
name: 湖朋
time: 2014-10-30 12:16
title: 人工智能毁灭人类，马斯克是在危言耸听嘛？
---
特斯拉公司CEO、被称为“现实版钢铁侠”的艾伦?马斯克，最近似乎患上了“人工智能恐惧症”。不但在Twitter上不止一次表达对人工智能的担忧，将人工智能的威胁与核威胁或是科幻电影《终结者》的现实版相类比，近日还在麻省理工的一场公开访谈中，把人工智能比作神话中的远古术士“召唤恶魔”的魔法——“每个巫师都声称自己可以控制所召唤的恶魔，但没有一个是最终成功的；因此，只要稍有不慎，人工智能就会为研究它和使用它的人带来无法预估的恶果”。 初看到这些话时只是有点诧异。一个公认的“科技狂人”，半年前刚投资了一家人工智能领域研究图像识别技术的创业公司，怎么对人工智能的态度发生180度的转变？ 更诧异的是，居然有人开始把这理解为马斯克对科技的敬畏之心，或是体现出马斯克高人一等的人文关怀等等，为之痴醉不已。那么问题来了—— 有没有不需要加以控制的科技？ 之所以把这个问题放在一开始，是想说明，马斯克的科技担忧也好，人文关怀也好，都是正确的废话。人们对人工智能，乃至广义科技的担忧和恐慌由来已久——至少比1984年上映的《终结者》要早得多。马斯克的时下言论，说实在的，除了语言上的刺激性，并没有为这一阵营增添什么新奇的论题。 从科技的本质讲，就是一柄双刃剑。科技能为人类社会改进提供多大的动力，就意味着它反过来蕴含着多大的破坏性。火药如是，核能如是，基因科技亦如是。经历过切尔诺贝利、山羊多莉的现代社会，警惕科技潜在的失控风险，可以算是基本常识了吧？所以今天反思人工智能使用不慎会带来灾难，好比说菜刀使用不慎会割伤手指，有什么好追捧的呢？ 而且，马斯克将人工智能的潜在威胁与核威胁相类比并不贴切。核威胁是一种现实的威胁，它不仅在技术上已经成熟，而且核武器已经被大量制造出来；不仅仅在军事上很现实，对于居住在核电站附近的人同样很现实。 好吧，抛开这个被好莱坞商业大片用滥了的核威胁，就人工智能目前的发展水平而言，其科技反思的典范资格，甚至还比不上同为21世纪三大尖端技术的基因工程。尤其是基因工程与优生学相结合所引发的潜在威胁，对我们的警醒无疑更为现实和直接，比如最近在看的哈佛著名学者桑德尔（Michael J. Sandel）的《反对完美（The Case Ag人工智能nst Perfection）》。因为马斯克的话就表示忧虑的人，要是有人说《超体》其实也是有可能实现的，你们会不会睡不着觉、吃不下饭？ 人工智能怎样才算失控？ 这个问题，是我无法忍受吹捧马斯克“人工智能恶魔论”的人最关键的原因。听马斯克说人工智能失控，就一口一个失控，像台复读机一样。谁来解释给我听，人工智能究竟怎么算是失控？ 类似社会制度对人工智能的失控（比如被某狂人操控）、或是将人工智能直接运用于无法逆转的关键性领域（比如控制人类生育、动手挖开地核等不靠谱的事儿）而失控等，最基本的前提还是人工智能已经达到了高度拟人阶段。 什么算是高度拟人？就是人工智能必须真的能具备（或模仿）人类的独立思考、价值判断乃至审美-创造等精神活动的能力。而这也意味着，人工智能要么能实现对人类思维非算法特质（如察言观色、灵感、审美、洞察力和创造力等）的模拟，要么是实现了人类精神的强物理还原，即认为所有的人类精神活动都可以化约为某种（哪怕极其复杂）的算法运算。 解决这类人工智能完备性难题（人工智能-Complete or 人工智能-Hard Problems）的两大逻辑方向，到底哪一种更有可能（或许在许多研究者看来，也可以说，哪一种更不可能）？这在人工智能领域依然是未知之数。这其中所需要跨越的理论门槛，并不是“哈利·波特们”一句简单的“守护神呼唤咒语（Expecto Patronum）”就可以解决的。 人工智能是需要被马上遏制的恶魔？ 提出这个问题，是想说明我们还必须将对人工智能发展的抽象探讨，与人工智能技术的现实应用区别开来。事实上，尽管公众对于运用人工智能存在不少的疑虑和担忧，但我们的生活已经有了大量的人工智能技术的应用。 在上世纪八九十年代的“第二季人工智能寒冬（AI winter of 1987-1993）”以来，人工智能的研究共同体为了对抗这一轮的资金萧条寒流，不得不将大量的精力放在人工智能技术的实际应用开发上，从而不但引发了以数据统计方法和演示实验为特征的新一轮经验主义研究范式（empiricist paradigm）兴起，而且也使得大量的人工智能技术进入到普罗大众的日常生活中来。 例如大家最为担心的智能机器人，实际上已经用于许多高风险和对人类健康有害的工作场所，包括核电站和矿井。此外，更普遍的机器人运用则是工业机器人，为人熟知的就有在亚马逊仓库中自动装卸货物的机器人，以及富士康生产线上装配零件的机器人。因此，当大众还对人工智能怀有某种不确知的恐慌时，其实早已在生活中享用着大量人工智能技术所带来的便利了。 对人工智能的忧虑究竟源自何来？ 自从十七世纪帕斯卡尔（B. Pascal）和莱布尼茨（G.W. von Leibniz）的机械计算器问世以来，人们对于人工智能的态度，就一直处于既盼望又恐惧的矛盾情结中。实际上，人们对于人工智能的这种由来已久的忧虑，并不仅仅是忧虑人类是否最终无法掌控自己所创造的科技那么简单，它背后实际上折射出某种人类对于自身存在独特性可能遭到摧毁，以及对于人类未来不确定性的某种不安。 的确，人工智能的发展存在一定风险，但这对于任何科技而言都是一样的。例如前面提到的基因工程技术，对人类未来的整体性威胁，并不见得就一定比人工智能来的要小。但这并非我们视之为魔鬼的好理由。 这是上帝与撒旦在科技与人性领域的双重较量，人类的有限性使得我们对不确定性的体验日益增加。但是我们依然有理由保持谨慎的乐观。至少单就技术而言，人工智能远未到达“生存还是毁灭”的分叉口。当马斯克或其他类似的人工智能批评者借用科幻电影（如《终结者》）或科幻小说来形容人工智能对人类整体的威胁之时，他们其实只是说出了这个故事的一半可能性，即悲观的那一半，而且还并不完整。即使站在他们的角度，我们也同样得不出“不作为”的结论。 就让我们也借用科幻小说的例子来作一结尾吧。看过《三体》的读者，几乎没有不对大刘（刘慈欣）对“宇宙动力学”两大定理的刻画和对类似于黑暗森林的宇宙的描绘印象深刻的，同时也很可能会触发我们对于外星文明威胁的忧虑：我们可能真的身处类似黑暗森林的宇宙中，因此，地外文明与我们之间实际上存在某种潜在的敌对关系。但是，即使这样，这种担忧和恐惧也并不应成为我们停下脚步，不继续探索宇宙、发展太空技术的好理由。在某种意义上，我们对人工智能的恐惧也与此类似：对于宇宙与自然，我们的确应该心怀敬畏，但却不应停下脚步。毕竟，在我们没有到达实际的分叉点之前，继续前进无疑是唯一合理的选择。

特斯拉公司CEO、被称为“现实版钢铁侠”的艾伦?马斯克，最近似乎患上了“人工智能恐惧症”。不但在Twitter上不止一次表达对人工智能的担忧，将人工智能的威胁与核威胁或是科幻电影《终结者》的现实版相类比，近日还在麻省理工的一场公开访谈中，把人工智能比作神话中的远古术士“召唤恶魔”的魔法——“每个巫师都声称自己可以控制所召唤的恶魔，但没有一个是最终成功的；因此，只要稍有不慎，人工智能就会为研究它和使用它的人带来无法预估的恶果”。

初看到这些话时只是有点诧异。一个公认的“科技狂人”，半年前刚投资了一家人工智能领域研究图像识别技术的创业公司，怎么对人工智能的态度发生180度的转变？

更诧异的是，居然有人开始把这理解为马斯克对科技的敬畏之心，或是体现出马斯克高人一等的人文关怀等等，为之痴醉不已。那么问题来了——

之所以把这个问题放在一开始，是想说明，马斯克的科技担忧也好，人文关怀也好，都是正确的废话。人们对人工智能，乃至广义科技的担忧和恐慌由来已久——至少比1984年上映的《终结者》要早得多。马斯克的时下言论，说实在的，除了语言上的刺激性，并没有为这一阵营增添什么新奇的论题。

从科技的本质讲，就是一柄双刃剑。科技能为人类社会改进提供多大的动力，就意味着它反过来蕴含着多大的破坏性。火药如是，核能如是，基因科技亦如是。经历过切尔诺贝利、山羊多莉的现代社会，警惕科技潜在的失控风险，可以算是基本常识了吧？所以今天反思人工智能使用不慎会带来灾难，好比说菜刀使用不慎会割伤手指，有什么好追捧的呢？

而且，马斯克将人工智能的潜在威胁与核威胁相类比并不贴切。核威胁是一种现实的威胁，它不仅在技术上已经成熟，而且核武器已经被大量制造出来；不仅仅在军事上很现实，对于居住在核电站附近的人同样很现实。

好吧，抛开这个被好莱坞商业大片用滥了的核威胁，就人工智能目前的发展水平而言，其科技反思的典范资格，甚至还比不上同为21世纪三大尖端技术的基因工程。尤其是基因工程与优生学相结合所引发的潜在威胁，对我们的警醒无疑更为现实和直接，比如最近在看的哈佛著名学者桑德尔（Michael J. Sandel）的《反对完美（The Case Ag人工智能nst Perfection）》。因为马斯克的话就表示忧虑的人，要是有人说《超体》其实也是有可能实现的，你们会不会睡不着觉、吃不下饭？

这个问题，是我无法忍受吹捧马斯克“人工智能恶魔论”的人最关键的原因。听马斯克说人工智能失控，就一口一个失控，像台复读机一样。谁来解释给我听，人工智能究竟怎么算是失控？

类似社会制度对人工智能的失控（比如被某狂人操控）、或是将人工智能直接运用于无法逆转的关键性领域（比如控制人类生育、动手挖开地核等不靠谱的事儿）而失控等，最基本的前提还是人工智能已经达到了高度拟人阶段。

什么算是高度拟人？就是人工智能必须真的能具备（或模仿）人类的独立思考、价值判断乃至审美-创造等精神活动的能力。而这也意味着，人工智能要么能实现对人类思维非算法特质（如察言观色、灵感、审美、洞察力和创造力等）的模拟，要么是实现了人类精神的强物理还原，即认为所有的人类精神活动都可以化约为某种（哪怕极其复杂）的算法运算。

解决这类人工智能完备性难题（人工智能-Complete or 人工智能-Hard Problems）的两大逻辑方向，到底哪一种更有可能（或许在许多研究者看来，也可以说，哪一种更不可能）？这在人工智能领域依然是未知之数。这其中所需要跨越的理论门槛，并不是“哈利·波特们”一句简单的“守护神呼唤咒语（Expecto Patronum）”就可以解决的。

提出这个问题，是想说明我们还必须将对人工智能发展的抽象探讨，与人工智能技术的现实应用区别开来。事实上，尽管公众对于运用人工智能存在不少的疑虑和担忧，但我们的生活已经有了大量的人工智能技术的应用。

在上世纪八九十年代的“第二季人工智能寒冬（AI winter of 1987-1993）”以来，人工智能的研究共同体为了对抗这一轮的资金萧条寒流，不得不将大量的精力放在人工智能技术的实际应用开发上，从而不但引发了以数据统计方法和演示实验为特征的新一轮经验主义研究范式（empiricist paradigm）兴起，而且也使得大量的人工智能技术进入到普罗大众的日常生活中来。

例如大家最为担心的智能机器人，实际上已经用于许多高风险和对人类健康有害的工作场所，包括核电站和矿井。此外，更普遍的机器人运用则是工业机器人，为人熟知的就有在亚马逊仓库中自动装卸货物的机器人，以及富士康生产线上装配零件的机器人。因此，当大众还对人工智能怀有某种不确知的恐慌时，其实早已在生活中享用着大量人工智能技术所带来的便利了。

自从十七世纪帕斯卡尔（B. Pascal）和莱布尼茨（G.W. von Leibniz）的机械计算器问世以来，人们对于人工智能的态度，就一直处于既盼望又恐惧的矛盾情结中。实际上，人们对于人工智能的这种由来已久的忧虑，并不仅仅是忧虑人类是否最终无法掌控自己所创造的科技那么简单，它背后实际上折射出某种人类对于自身存在独特性可能遭到摧毁，以及对于人类未来不确定性的某种不安。

的确，人工智能的发展存在一定风险，但这对于任何科技而言都是一样的。例如前面提到的基因工程技术，对人类未来的整体性威胁，并不见得就一定比人工智能来的要小。但这并非我们视之为魔鬼的好理由。

这是上帝与撒旦在科技与人性领域的双重较量，人类的有限性使得我们对不确定性的体验日益增加。但是我们依然有理由保持谨慎的乐观。至少单就技术而言，人工智能远未到达“生存还是毁灭”的分叉口。当马斯克或其他类似的人工智能批评者借用科幻电影（如《终结者》）或科幻小说来形容人工智能对人类整体的威胁之时，他们其实只是说出了这个故事的一半可能性，即悲观的那一半，而且还并不完整。即使站在他们的角度，我们也同样得不出“不作为”的结论。

就让我们也借用科幻小说的例子来作一结尾吧。看过《三体》的读者，几乎没有不对大刘（刘慈欣）对“宇宙动力学”两大定理的刻画和对类似于黑暗森林的宇宙的描绘印象深刻的，同时也很可能会触发我们对于外星文明威胁的忧虑：我们可能真的身处类似黑暗森林的宇宙中，因此，地外文明与我们之间实际上存在某种潜在的敌对关系。但是，即使这样，这种担忧和恐惧也并不应成为我们停下脚步，不继续探索宇宙、发展太空技术的好理由。在某种意义上，我们对人工智能的恐惧也与此类似：对于宇宙与自然，我们的确应该心怀敬畏，但却不应停下脚步。毕竟，在我们没有到达实际的分叉点之前，继续前进无疑是唯一合理的选择。

