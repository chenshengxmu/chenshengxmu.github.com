---
layout: post
url: https://www.huxiu.com/article/166955
name: 连线
time: 2016-10-13 17:50
title: 人工智能的价值观比技术更重要，奥巴马认为美国能做好，但是俄罗斯、中国、伊朗就......
---
图片来自连线，Christopher Anderson摄

虎嗅注：美国总统奥巴马和麻省理工学院媒体实验室主任伊藤穰一接受了《连线》杂志记者Scott Dadich关于人工智能话题的采访，谈到了人工智能价值观的设立以及政府在这期间扮演的角色问题。原文来自《连线》，原文标题为《Barack Obama, Neural Nets, Self-driving Cars, And The Future Of The World》，虎嗅摘编翻译。

DADICH：我想把话题集中在人工智能上面，它已经从科幻小说里走入了现实，并正在改变我们的生活。是什么时候你意识到真正的AI（人工智能）时代到来了？

奥巴马：我的观察是，它已经以各种方式渗入了我们的生活，只是我们没注意到；部分原因是

流行文化对人工智能的描绘存在偏见。《连线》的读者们可能都了解，通用人工智能和专用人工智能之间存在差别。科幻小说里描写的是通用人工智能，对吧？里面会提到，计算机变得比人类聪明，人类越来越没用，之后我们成了他们喂养的宠物，变成了黑客帝国。

但根据我和顶尖科学顾问的交流来看，我们距离那种程度还很远。专用AI已经渗透到了生活的各个方面，比如医药、交通、电力输送，对经济生产效率有巨大的提升。如果妥善应用，它可以带来繁荣和机会。不过也存在不利影响，如导致就业机会减少，我们需要对此进行研究，AI可能导致不平等、影响工资水平等。

伊藤穰一：我很多麻省理工的学生认为，如果他们能够做出科幻小说中的通用AI的话，我们不必担心政治、社会等问题。他们认为机器会给我们答案。

但是他们低估了这其中的难度，我觉得今年起人工智能不再是一个计算机领域的问题。每个人都需要理解为什么AI很重要。在Media Lab，我们使用“延展智能”这个术语，它指我们需要为AI建立社会价值观。

奥巴马：就自动驾驶来说，机器可以快速地做出一系列决定，大大减少交通死亡事故，提高交通效率，还能解决导致地球变暖的碳排放问题。但伊藤提出了一个更讲究的问题，我们应该赋予自动驾驶汽车怎样的价值观。经典问题是：如果自动驾驶汽车即将撞上行人时，你是否会紧急避让行人，但车可能撞墙甚至导致驾驶员身亡？这是一个道德的问题，谁来为AI设置这些规则？

DADICH：当我们开始涉及伦理问题时，政府扮演怎样的角色？

奥巴马：我一直在思考AI的监管结构问题，在技术早期，应该百花齐放。政府应该从“轻”管理，大力投资研究，确保在基础研究和应用研究之间的对话。随着技术的出现与成熟，如何将AI纳入已有的监管结构中成了一个更为棘手的问题，政府需要插手更多。

DADICH: 当我们讨论“延展智能”时，政府、私企以及学术界，哪一个会成为它的研究中心？

伊藤穰一：我认为麻省理工学院会认为中心应该在麻省理工学院。（笑）从历史来看，研究中心往往是由一批拿政府资助的学术人才组成的。但是现在，大多数十亿美元级的实验室都是商业经营的。

奥巴马：我们了解它们背后的赞助人心理，如果你和拉里·佩奇或者其他人，他们的态度可想而知：“我们不能被官僚拖累我们追赶独角兽的速度。”

这种结果的原因之一是，国家对于基础性研究的承诺减少了。我们对集体行为的信心已经被削弱，部分是因为是思想和言论上的转变。

我们仍然会用登月行动做类比，即使在50年后，它仍是一个伟大科技壮举。有人提醒我，登月计划曾耗资GDP的0.5%，类比如今，相当于我们每年需花费800亿美元在AI上面。事实上，我们现在投入不足10亿美元。AI领域的投入无疑会加速，但是我们需要了解，如果想要这种突破性技术符合多元文化价值观，政府的资助是必须的。如果政府没有参与资助，那么技术中的价值观会跑偏。

DADICH：商业化的科技创新与航空航天等创新相比，有何区别，我们如何察觉这之间的转变？

奥巴马：我已经强调，政府资助项目并收集数据，并不意味着政府在积累数据或者只为了军事用途。举个具体例子：我们精确医学的某个项目需要从美国各地获得大量不同的人类基因组数据。但是，我们并没有将斯坦福和哈佛的样本数据商业化，而是所有人都是可以自由访问整个基因组数据库。这是因为我们有一套共同价值观和体系结构，它可以确保研究结果被共享，而不被某一组织商业化。

DADICH：另外，人工智能是否会掀起新一轮的军备竞赛？

奥巴马：我认为在围绕网路安全，尤其是AI上建立国际规范、协议、验证机制处于初级阶段。这让问题变得有趣，因为进攻和防守的界限还非常模糊。如果对政府不信任，那么建立上述内容会变得很艰难。当其他国家注意到美国卓越的网络力量时，我们是时候说，“我们愿意约束自己，如果你也约束你自己的话”。挑战来自那些最老练的国家——俄罗斯、中国、伊朗，它们没有体现出和我们一样的价值观和规范。我们必须将AI作为国际问题去面对，以便提高我们的效率。

